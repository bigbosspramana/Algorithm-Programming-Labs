{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wHOhX30KeS-pY-2pA5mTVKSSRqLTjQ8z",
      "authorship_tag": "ABX9TyMvAnVjMrrF41LLteEro7B2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bigbosspramana/Algorithm-Programming-Labs/blob/main/adaadaji.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing packages\n",
        "from ultralytics import YOLO\n",
        "from deep_translator import GoogleTranslator\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import itertools\n",
        "import array as arr\n",
        "import math\n",
        "\n",
        "# model\n",
        "model = YOLO(\"yolo-Weights/yolov8x.pt\")\n",
        "\n",
        "# img size\n",
        "w1, h1, w2, h2 = 150, 50, 490, 430\n",
        "\n",
        "# object classes\n",
        "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
        "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
        "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
        "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
        "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
        "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
        "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
        "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
        "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
        "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
        "              ]\n",
        "\n",
        "# Define path to the image file\n",
        "source = 'https://bot.telkom.club/Gilbert/Gambar.jpg'\n",
        "fileName = 'Gambar.jpg'\n",
        "\n",
        "# prepare empty arrays for results\n",
        "objList = []\n",
        "resultList = []\n",
        "\n",
        "# Run inference on the source\n",
        "results = model(source,stream=True)  # list of Results objects\n",
        "for r in results: # looping results\n",
        "        boxes = r.boxes\n",
        "        for box in boxes:\n",
        "          cls = int(box.cls[0])\n",
        "          confidence = math.ceil((box.conf[0]*100))/100 # getting confidence\n",
        "          print(f\"confidence of {classNames[cls]}: {confidence}\")\n",
        "          if confidence > 0.75: # selected via confidence\n",
        "            x1, y1, x2, y2 = box.xyxy[0]\n",
        "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "            x, y = x2 - x1, y2 - y1\n",
        "            print(\"center coords:\",x, y)\n",
        "            if (w1 < x and w2 > x) and (h1 < y and h2 > y): # selected by mid bounding box\n",
        "              # putting objects in selected lists\n",
        "              obj = GoogleTranslator(source='auto', target='id').translate(classNames[cls])\n",
        "              objList.append(obj)\n",
        "\n",
        "# # counting object quantities\n",
        "# print(objList)\n",
        "# for j in objList:\n",
        "#   resultList.append(str(objList.count(j)) + \" \" + j)\n",
        "#   for d in range(0, objList.count(j)):\n",
        "#     objList.remove(j)\n",
        "\n",
        "# parsing duplicate objects\n",
        "for j in objList:\n",
        "  resultList.append(j)\n",
        "  for d in range(0, objList.count(j)):\n",
        "    objList.remove(j)\n",
        "\n",
        "# parsing result list\n",
        "if len(resultList) > 0:\n",
        "  text = \"Ada \"\n",
        "  for h in range(0, len(resultList)):\n",
        "    text += resultList[h][:1].upper() + resultList[h][1:].lower()\n",
        "    if len(resultList) > 1:\n",
        "      if h < len(resultList) - 2:\n",
        "        text += \", \"\n",
        "      elif h < len(resultList) - 1:\n",
        "        text += \", dan \"\n",
        "  text += \" di depanmu!\"\n",
        "else:\n",
        "  text = \"Tidak ada apa-apa di depanmu!\"\n",
        "print(f\"\\n{text}\")\n",
        "\n",
        "# tts\n",
        "tts = gTTS(text=text, lang='id', slow=False)\n",
        "tts.save(\"tts.mp3\")\n",
        "os.system(\"mpg321 tts.mp3\")\n",
        "os.remove(\"tts.mp3\")\n",
        "\n",
        "# Deleting the image\n",
        "os.remove(fileName)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATXJnYX5w-Br",
        "outputId": "91a1d8c5-d42e-4378-fb46-6784fb49beb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading https://bot.telkom.club/Gilbert/Gambar.jpg to 'Gambar.jpg'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 398k/398k [00:00<00:00, 748kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confidence of chair: 0.95\n",
            "center coords: 390 413\n",
            "confidence of chair: 0.94\n",
            "center coords: 420 271\n",
            "confidence of chair: 0.93\n",
            "center coords: 257 380\n",
            "confidence of chair: 0.91\n",
            "center coords: 293 326\n",
            "confidence of chair: 0.89\n",
            "center coords: 130 189\n",
            "confidence of chair: 0.87\n",
            "center coords: 372 173\n",
            "confidence of chair: 0.86\n",
            "center coords: 112 163\n",
            "confidence of person: 0.85\n",
            "center coords: 318 584\n",
            "confidence of chair: 0.83\n",
            "center coords: 243 359\n",
            "confidence of cup: 0.8\n",
            "center coords: 54 61\n",
            "confidence of diningtable: 0.7\n",
            "confidence of chair: 0.59\n",
            "confidence of laptop: 0.56\n",
            "confidence of chair: 0.55\n",
            "confidence of chair: 0.42\n",
            "confidence of diningtable: 0.42\n",
            "confidence of handbag: 0.38\n",
            "confidence of bottle: 0.33\n",
            "confidence of diningtable: 0.26\n",
            "image 1/1 /content/Gambar.jpg: 288x640 1 person, 1 handbag, 1 bottle, 1 cup, 11 chairs, 3 dining tables, 1 laptop, 1836.1ms\n",
            "Speed: 3.4ms preprocess, 1836.1ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
            "\n",
            "Ada Kursi di depanmu!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip install deep_translator\n",
        "!pip install gtts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzt5GvVEe2tN",
        "outputId": "c999d4d6-bb1c-4039-cb94-ea68174a8fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.215-py3-none-any.whl (645 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/645.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/645.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m553.0/645.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.7/645.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.215\n",
            "Collecting deep_translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep_translator) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep_translator) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2023.7.22)\n",
            "Installing collected packages: deep_translator\n",
            "Successfully installed deep_translator-1.11.4\n",
            "Collecting gtts\n",
            "  Downloading gTTS-2.4.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2023.7.22)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import math\n",
        "# start webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(3, 640)\n",
        "cap.set(4, 480)\n",
        "\n",
        "# model\n",
        "model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
        "\n",
        "# object classes\n",
        "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
        "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
        "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
        "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
        "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
        "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
        "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
        "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
        "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
        "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
        "              ]\n",
        "\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    results = model(img, stream=True)\n",
        "\n",
        "    # coordinates\n",
        "    for r in results:\n",
        "        boxes = r.boxes\n",
        "\n",
        "        for box in boxes:\n",
        "            # bounding box\n",
        "            x1, y1, x2, y2 = box.xyxy[0]\n",
        "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
        "\n",
        "            # put box in cam\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
        "\n",
        "            # confidence\n",
        "            confidence = math.ceil((box.conf[0]*100))/100\n",
        "            print(\"Confidence --->\",confidence)\n",
        "\n",
        "            # class name\n",
        "            cls = int(box.cls[0])\n",
        "            print(\"Class name -->\", classNames[cls])\n",
        "\n",
        "            # object details\n",
        "            org = [x1, y1]\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            fontScale = 1\n",
        "            color = (255, 0, 0)\n",
        "            thickness = 2\n",
        "\n",
        "            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
        "\n",
        "    # cv2.imshow('Webcam', img)\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a_R46CEr781w",
        "outputId": "3cf825a8-51f9-4947-94a6-31ad201da2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ 'source' is missing. Using 'source=/usr/local/lib/python3.10/dist-packages/ultralytics/assets'.\n",
            "\n",
            "Confidence ---> 0.88\n",
            "Class name --> bus\n",
            "Confidence ---> 0.87\n",
            "Class name --> person\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Confidence ---> 0.83\n",
            "Class name --> person\n",
            "Confidence ---> 0.27\n",
            "Class name --> person\n",
            "Confidence ---> 0.26\n",
            "Class name --> stop sign\n",
            "image 1/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 220.6ms\n",
            "Confidence ---> 0.84\n",
            "Class name --> person\n",
            "Confidence ---> 0.82\n",
            "Class name --> person\n",
            "Confidence ---> 0.3\n",
            "Class name --> tie\n",
            "image 2/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/zidane.jpg: 384x640 2 persons, 1 tie, 140.1ms\n",
            "Speed: 3.9ms preprocess, 180.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ⚠️ 'source' is missing. Using 'source=/usr/local/lib/python3.10/dist-packages/ultralytics/assets'.\n",
            "\n",
            "Confidence ---> 0.88\n",
            "Class name --> bus\n",
            "Confidence ---> 0.87\n",
            "Class name --> person\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Confidence ---> 0.83\n",
            "Class name --> person\n",
            "Confidence ---> 0.27\n",
            "Class name --> person\n",
            "Confidence ---> 0.26\n",
            "Class name --> stop sign\n",
            "image 1/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 165.7ms\n",
            "Confidence ---> 0.84\n",
            "Class name --> person\n",
            "Confidence ---> 0.82\n",
            "Class name --> person\n",
            "Confidence ---> 0.3\n",
            "Class name --> tie\n",
            "image 2/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/zidane.jpg: 384x640 2 persons, 1 tie, 129.2ms\n",
            "Speed: 3.1ms preprocess, 147.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ⚠️ 'source' is missing. Using 'source=/usr/local/lib/python3.10/dist-packages/ultralytics/assets'.\n",
            "\n",
            "Confidence ---> 0.88\n",
            "Class name --> bus\n",
            "Confidence ---> 0.87\n",
            "Class name --> person\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Confidence ---> 0.83\n",
            "Class name --> person\n",
            "Confidence ---> 0.27\n",
            "Class name --> person\n",
            "Confidence ---> 0.26\n",
            "Class name --> stop sign\n",
            "image 1/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 170.6ms\n",
            "Confidence ---> 0.84\n",
            "Class name --> person\n",
            "Confidence ---> 0.82\n",
            "Class name --> person\n",
            "Confidence ---> 0.3\n",
            "Class name --> tie\n",
            "image 2/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/zidane.jpg: 384x640 2 persons, 1 tie, 132.5ms\n",
            "Speed: 3.5ms preprocess, 151.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ⚠️ 'source' is missing. Using 'source=/usr/local/lib/python3.10/dist-packages/ultralytics/assets'.\n",
            "\n",
            "Confidence ---> 0.88\n",
            "Class name --> bus\n",
            "Confidence ---> 0.87\n",
            "Class name --> person\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Confidence ---> 0.83\n",
            "Class name --> person\n",
            "Confidence ---> 0.27\n",
            "Class name --> person\n",
            "Confidence ---> 0.26\n",
            "Class name --> stop sign\n",
            "image 1/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 157.6ms\n",
            "Confidence ---> 0.84\n",
            "Class name --> person\n",
            "Confidence ---> 0.82\n",
            "Class name --> person\n",
            "Confidence ---> 0.3\n",
            "Class name --> tie\n",
            "image 2/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/zidane.jpg: 384x640 2 persons, 1 tie, 123.0ms\n",
            "Speed: 3.0ms preprocess, 140.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ⚠️ 'source' is missing. Using 'source=/usr/local/lib/python3.10/dist-packages/ultralytics/assets'.\n",
            "\n",
            "Confidence ---> 0.88\n",
            "Class name --> bus\n",
            "Confidence ---> 0.87\n",
            "Class name --> person\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Confidence ---> 0.83\n",
            "Class name --> person\n",
            "Confidence ---> 0.27\n",
            "Class name --> person\n",
            "Confidence ---> 0.26\n",
            "Class name --> stop sign\n",
            "image 1/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 153.0ms\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c7f79462070e>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;31m# Pass the last request to the generator and get its response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# We let the exceptions raised above by the generator's `.throw` or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_predict_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_predict_batch_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;31m# Read image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mim0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# BGR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Image Not Found {path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg' save=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qUGw7Pl2o49",
        "outputId": "57653f46-1082-44e5-ba95-41ac8098deb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.213 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n",
            "100% 476k/476k [00:00<00:00, 15.6MB/s]\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 392.1ms\n",
            "Speed: 14.2ms preprocess, 392.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    }
  ]
}